\documentclass{article}

\usepackage{amsmath, amsthm, bm, physics, enumerate, siunitx, dirtytalk, tikz}
\usepackage{hyperref}
\usetikzlibrary{calc, patterns}

\newtheorem{theorem}{Theorem}
% \newtheorem{lemma}{Lemma}

% \providecommand{\levicivita}[3]{%
%   \ensuremath{\varepsilon_{{#1}{#2}{#3}}}
% }


% ------------------------------------------------------------------------------
\title{Formulas for finite differences}
\author{Wojciech Sadowski}

\begin{document}
\maketitle
\section{Basics}
\paragraph{Taylor series}
\[
  u(x + h) = u(x) 
  + \frac{h}{1!}\pdv{u}{x} 
  + \frac{h^2}{2!}\pdv[2]{u}{x} 
  + \frac{h^3}{3!}\pdv[3]{u}{x} + \dots
\]

\section{One dimension}
\paragraph{Forward difference}
\[
  u(x + h) = u(x) 
  + \frac{h}{1!}\pdv{u}{x} 
  + \frac{h^2}{2!}\pdv[2]{u}{x} +
  + \frac{h^3}{3!}\pdv[3]{u}{x} +
  \mathcal{O}\qty(h^4)
\]
We divide by \(h\):
\[
  \frac{u(x + h)}{h} = \frac{u(x)}{h} 
  + \pdv{u}{x} 
  + \frac{h}{2!}\pdv[2]{u}{x} 
  + \frac{h^2}{3!}\pdv[3]{u}{x} 
  + \mathcal{O}\qty(h^3)
\]
Rearange:
\begin{equation}\label{eq::forward}
   \pdv{u}{x} 
   = \frac{u(x + h) - u(x)}{h}  
  - \frac{h}{2!}\pdv[2]{u}{x} 
  - \frac{h^2}{3!}\pdv[3]{u}{x} 
  + \mathcal{O}\qty(h^3)
\end{equation}
Finally:
\[
   \pdv{u}{x} 
   = \frac{u(x + h) - u(x)}{h}  + \mathcal{O}\qty(h)
\]

\paragraph{Backward difference}
\[
  u(x - h) = u(x) 
  - \frac{h}{1!}\pdv{u}{x} 
  + \frac{h^2}{2!}\pdv[2]{u}{x} 
  - \frac{h^3}{3!}\pdv[3]{u}{x} 
  + \mathcal{O}\qty(h^4)
\]
We divide by \(h\):
\[
  \frac{u(x - h)}{h} = \frac{u(x)}{h} 
  -\pdv{u}{x} 
  + \frac{h}{2!}\pdv[2]{u}{x} +
  - \frac{h^2}{3!}\pdv[3]{u}{x} +
  \mathcal{O}\qty(h^3)
\]
Rearange:
\begin{equation}\label{eq::backward}
   \pdv{u}{x} 
   = \frac{u(x) - u(x-h)}{h}  
  + \frac{h}{2!}\pdv[2]{u}{x} 
  - \frac{h^2}{3!}\pdv[3]{u}{x} 
  + \mathcal{O}\qty(h^3)
\end{equation}
Finally:
\[
   \pdv{u}{x} 
   = \frac{u(x) - u(x - h)}{h}  + \mathcal{O}\qty(h)
\]
\paragraph{Central difference}
Take a sum of forward and backward, \autoref{eq::forward} and 
\autoref{eq::backward}:

\begin{equation}\label{eq::backward}
   2\pdv{u}{x} 
   = \frac{u(x+h) - u(x-h)}{h}  
  - \frac{2 h^2}{3!}\pdv[3]{u}{x} 
  + \mathcal{O}\qty(h^3)
\end{equation}
Divide by two:
\begin{equation}\label{eq::backward}
   \pdv{u}{x} 
   = \frac{u(x+h) - u(x-h)}{2h}  
  - \frac{1 h^2}{3!}\pdv[3]{u}{x} 
  + \mathcal{O}\qty(h^3)
\end{equation}
Finally:
\begin{equation}\label{eq::backward}
   \pdv{u}{x} 
   = \frac{u(x+h) - u(x-h)}{2h}  
  + \mathcal{O}\qty(h^2)
\end{equation}

\paragraph{Central difference of second derivative}
It is not exactly central difference of a central difference. That would have 
a wide stencil. Bad. Instead try writing at halfs.
\[
  u''(x) = \frac{u'(x+h/2) - u'(x-h/2)}{h}
\]
\[
  u'(x\pm h) = \frac{u(x\pm h/2 + h/2) - u(x \pm h/2 - h/2)}{h}
\]
Pluging in\dots
\[
  u''(x) = \frac{ u(x + h) - 2 u(x) + u(x-h) }{h^2}
\]

\section{Solving systems of equations}
\paragraph{Gauss seidel formula}
From Wikipedia. We have 
\[
  A =
\underbrace{
\begin{bmatrix} a_{11} & 0 & \cdots & 0 \\ a_{21} & a_{22} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix}
}_{\textstyle L_*}
+
\underbrace{
\begin{bmatrix} 0 & a_{12} & \cdots & a_{1n} \\ 0 & 0 & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \end{bmatrix}
}_{\textstyle U}
.
\]
We do:
\begin{alignat}{1}
A\mathbf x &= \mathbf b \\
(L_*+U) \mathbf x &= \mathbf b \\
L_* \mathbf x+U\mathbf x &= \mathbf b \\
L_* \mathbf{x} &= \mathbf{b} - U \mathbf{x}
\end{alignat}

The Gaussâ€“Seidel method now solves the left hand side of this expression for $\mathbf{x}$, 
using previous value for $\mathbf{x}$ on the right hand side. Analytically, 
this may be written as:
\[
  \mathbf{x}^{(k+1)} = L_*^{-1} \left(\mathbf{b} - U \mathbf{x}^{(k)}\right).
\]

However, by taking advantage of the triangular form of \(L_{*}\), the elements of 
\(\mathbf {x} ^{(k+1)}\) can be computed sequentially for each row \(i\) using 
forward substitution:
\[
  x^{(k+1)}_i  = \frac{1}{a_{ii}} \left(b_i - \sum_{j=1}^{i-1}a_{ij}x^{(k+1)}_j - \sum_{j=i+1}^{n}a_{ij}x^{(k)}_j \right),\quad i=1,2,\dots,n
\]

\section{COSI/U4}
\subsection{Instationary diffusion}
\paragraph{Forward Euler scheme}
It is an explicit scheme in time (from Taylor expansion):
\[
  u(t^{n+1}, x) = u(t^{n}, x) + \Delta t f\qty(t^{n}, x, u(t^{n}, x))
\]
\paragraph{Implicit Euler}
\[
  u(t^{n+1}, x) = u(t^{n}, x) + \Delta t f\qty(t^{n+1}, x, u(t^{n+1}, x))
\]

\paragraph{Heat equation}
\[
  \pdv{T}{t} = \alpha \pdv[2]{T}{x} = \dfrac{\lambda}{\rho c_p}\pdv[2]{T}{x}
\]

Discretised form
\[
  \dfrac{T_i^{n+1} - T_i^n}{\Delta t} = \alpha\dfrac{T^n_{i+1} - 2 T^n_{i} + T^n_{i-1}}{\qty(\Delta x)^2 }
\]
\[
  T_i^{n+1} = T_i^n + \dfrac{\alpha\Delta t}{\qty(\Delta x)^2}\qty[T^n_{i+1} - 2 T^n_{i} + T^n_{i-1}]
\]
\[
  T_i^{n+1} = \qty(1 - \dfrac{2\alpha\Delta t}{\qty(\Delta x)^2})T_i^n 
  + \dfrac{\alpha\Delta t}{\qty(\Delta x)^2}\qty[T^n_{i+1}  + T^n_{i-1}]
\]

\subsection{Von Neumann stability analysis}
The von Neumann method is based on the decomposition of the errors into 
Fourier series. To illustrate the procedure, consider the one-dimensional 
heat equation
\[
  \pdv{T}{t} = \alpha \pdv[2]{T}{x} 
\]
defined on the spatial interval \(L\), which can be discretized in this case, 
using the FTCS discretization scheme as
\[
u_j^{n + 1} = u_j^n + r \left(u_{j + 1}^n - 2 u_j^n + u_{j - 1}^n \right),\quad
r = \frac{\alpha\, \Delta t}{\left( \Delta x \right)^2}
\]
and the solution \(u_j^{n}\) of the discrete equation approximates 
the analytical solution \(u(x,t)\) of the PDE on the grid.

Define the round-off error \(\epsilon_j^n\) as
\[
  \epsilon_j^n = N_j^n - u_j^n
\]
where \(u_j^n\) is the solution of the discretized equation that would be computed 
in the absence of round-off error, and \(N_j^n\) is the numerical solution. 
The error satisfies the solution since the exact solution does that as well.
\[
\epsilon_j^{n + 1} = \epsilon_j^n + r \left(\epsilon_{j + 1}^n - 2 \epsilon_j^n + \epsilon_{j - 1}^n \right)
\]
Both solution and error have the same behaviour with respect to time. We assume periodic 
conditions. Equation is linear, so we can say:
\[
\epsilon(x,t) = \sum_{m=-M}^{M} e_m = 
\sum_{m=-M}^{M} E_m(t) e^{{ i}  k_m x}
\]
The wavenumber is defined as 
\[
  k_m = \dfrac{\pi m}{L},\quad m = -M,\dots,-1,0,1,\dotsm M, \quad M = \dfrac{L}{\Delta X}
\]
The amplitude \(E_m\) is the function of time.
We can only consider one of the error frequencies:
\begin{align}
 \epsilon_j^n & = E_m(t) e^{ik_m x} \\
 \epsilon_j^{n+1} & = E_m(t+\Delta t)  e^{ik_m x} \\
 \epsilon_{j+1}^n & = E_m(t) e^{ik_m (x+\Delta x)} \\
 \epsilon_{j-1}^n & = E_m(t)  e^{ik_m (x-\Delta x)},
\end{align}
Inserting into the equations (I divided by \(E_m(t)\) for the sake of space):
\[
  \dfrac{E_m(t+\Delta t)  e^{ik_m x}}{E_m(t)} =  e^{ik_m x} 
+ r \left( e^{ik_m (x+\Delta x)} - 2 e^{ik_m x} +   e^{ik_m (x-\Delta x)} \right)
\]
Now dividing by the \(e^{i k_m x}\)
\[
  \dfrac{E_m(t+\Delta t) }{E_m(t)} =  1
+ r \left( e^{ik_m \Delta x} - 2  +   e^{-ik_m \Delta x} \right)
\]
If we set \(\phi = k_m \Delta x\), note that \(e^{i\phi} = i\sin\qty(\phi) + \cos\qty(\phi)\) and
remember that \(\sin\) is antysymmetric and \(\cos\) is symmetric
\[
  \dfrac{E_m(t+\Delta t) }{E_m(t)} =  1
+ r \left( i\sin\qty(\phi) + \cos\phi - 2  - i\sin\phi + \cos\phi \right)
\]
\[
  G = \dfrac{E_m(t+\Delta t) }{E_m(t)} =  1 - 2r \left(\cos\phi - 1\right) 
  = 1 + 4r\sin^2\dfrac{\phi}{2}
\]
We have also used the property of \(2\sin^2\qty(\phi/2) = 1-\cos\phi\). 
The condition for stability is \(|G| \neq 1\).
\[
   \left| 1 - 4 r \sin^2 (\theta /2) \right| \leq 1
\]
The \(\sin^2\) is always positive. 
\[
   4 r \sin^2 (\theta /2) \leq 2
\]



\end{document} 
